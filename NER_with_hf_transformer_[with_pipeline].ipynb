{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER-with-hf-transformer-[with-pipeline].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBPMH+MV8FgA16J6GuYido",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smf-9000/Named-Entity-Recognition/blob/main/NER_with_hf_transformer_%5Bwith_pipeline%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDdrfsG_Ht_5"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "[https://huggingface.co/transformers/custom_datasets.html\n",
        "https://huggingface.co/transformers/main_classes/pipelines.html#tokenclassificationpipeline]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX0_Skp_VK4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e6fd92-186e-45ad-91d3-4f098444c271"
      },
      "source": [
        "!pip install pandas transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7AA2ZZQOGM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ed9a89-df99-48b3-b38f-ab340e2ec785"
      },
      "source": [
        "! wget http://noisy-text.github.io/2017/files/wnut17train.conll"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-20 12:58:41--  http://noisy-text.github.io/2017/files/wnut17train.conll\n",
            "Resolving noisy-text.github.io (noisy-text.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to noisy-text.github.io (noisy-text.github.io)|185.199.108.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 493781 (482K) [application/octet-stream]\n",
            "Saving to: ‘wnut17train.conll.1’\n",
            "\n",
            "\rwnut17train.conll.1   0%[                    ]       0  --.-KB/s               \rwnut17train.conll.1 100%[===================>] 482.21K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-07-20 12:58:41 (19.8 MB/s) - ‘wnut17train.conll.1’ saved [493781/493781]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--nuOAJiPO99"
      },
      "source": [
        "from pathlib import Path\n",
        "import re\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6KCQYCmPRmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2c6955-4111-437f-d650-8525dfcc04b7"
      },
      "source": [
        "file_path = Path(\"/content/wnut17train.conll\")\n",
        "raw_text = file_path.read_text().strip()\n",
        "raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "\n",
        "token_docs = []\n",
        "tag_docs = []\n",
        "for doc in raw_docs:\n",
        "  tokens = []\n",
        "  tags = []\n",
        "  for line in doc.split('\\n'):\n",
        "    token, tag = line.split('\\t')\n",
        "    tokens.append(token)\n",
        "    tags.append(tag)\n",
        "  token_docs.append(tokens)\n",
        "  tag_docs.append(tags)\n",
        "\n",
        "print(token_docs[10])\n",
        "print(tag_docs[10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@Suzie55', 'whispering', 'cause', 'I', 'may', 'have', 'had', '1', 'too', 'many', 'vodka', \"'s\", 'last', 'night', 'and', 'am', 'a', 'lil', 'fragile', ',', 'hold', 'me', '?']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-product', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqUT4hlILw94",
        "outputId": "1b35efab-c610-4ea7-9db4-75b38a9171be"
      },
      "source": [
        "len(token_docs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cnOCHz8R7Qn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_tags, val_tags = train_test_split(token_docs, tag_docs, test_size=.2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjbttPqCSa1P"
      },
      "source": [
        "## encodings for our tokens and tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqQYYYENSWFV"
      },
      "source": [
        "unique_tags = set(tag for doc in tag_docs for tag in doc)\n",
        "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
        "id2tag = {id: tag for tag, id in tag2id.items()}\n",
        "\n",
        "# print(tag2id)\n",
        "# print(id2tag)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE4M5YmMfOSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4faddc26-05ac-4fb8-ede0-cb33ddaea4e6"
      },
      "source": [
        "id2tag"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'B-creative-work',\n",
              " 1: 'B-product',\n",
              " 2: 'O',\n",
              " 3: 'I-product',\n",
              " 4: 'B-location',\n",
              " 5: 'B-group',\n",
              " 6: 'I-corporation',\n",
              " 7: 'I-person',\n",
              " 8: 'I-group',\n",
              " 9: 'I-location',\n",
              " 10: 'I-creative-work',\n",
              " 11: 'B-person',\n",
              " 12: 'B-corporation'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C5r2bSnUSMH"
      },
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "val_encodings = tokenizer(val_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cer8jtaoYi9L"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "train_encodings={\n",
        "  'input_ids': [...],\n",
        "  'offset_mapping': [...]\n",
        "}\n",
        "\"the offset mapping gives us a tuple indicating the sub-token’s start position and end position relative to the original token it was split from\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovwBug5ZGLOr"
      },
      "source": [
        "train_encodings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6LurYWZYqEM"
      },
      "source": [
        "# https://huggingface.co/transformers/custom_datasets.html#token-classification-with-w-nut-emerging-entities\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def encode_tags(tags, encodings):\n",
        "  labels = [[tag2id[tag] for tag in doc] for doc in tags]\n",
        "  encoded_labels = []\n",
        "  for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "    # create an empty array of -100\n",
        "    doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "    arr_offset = np.array(doc_offset)\n",
        "\n",
        "    # set labels whose first offset position is 0 and the second is not 0\n",
        "    doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "    encoded_labels.append(doc_enc_labels.tolist())\n",
        "\n",
        "  return encoded_labels\n",
        "\n",
        "train_labels = encode_tags(train_tags, train_encodings)\n",
        "val_labels = encode_tags(val_tags, val_encodings)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "956RTIOjcHU8"
      },
      "source": [
        "print(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT2y1Zx-cXs2"
      },
      "source": [
        "import torch\n",
        "\n",
        "class WNUTDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "train_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
        "val_encodings.pop(\"offset_mapping\")\n",
        "train_dataset = WNUTDataset(train_encodings, train_labels)\n",
        "val_dataset = WNUTDataset(val_encodings, val_labels)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQnsykU4cpmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6fc6ed-554e-4b89-d7f4-2cbccb13ecc5"
      },
      "source": [
        "from transformers import DistilBertForTokenClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = DistilBertForTokenClassification.from_pretrained(\n",
        "                                                  'distilbert-base-cased',\n",
        "                                                  num_labels=len(unique_tags),\n",
        "                                                  id2label=id2tag,\n",
        "                                                  label2id=tag2id)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-creative-work\",\n",
            "    \"1\": \"B-product\",\n",
            "    \"2\": \"O\",\n",
            "    \"3\": \"I-product\",\n",
            "    \"4\": \"B-location\",\n",
            "    \"5\": \"B-group\",\n",
            "    \"6\": \"I-corporation\",\n",
            "    \"7\": \"I-person\",\n",
            "    \"8\": \"I-group\",\n",
            "    \"9\": \"I-location\",\n",
            "    \"10\": \"I-creative-work\",\n",
            "    \"11\": \"B-person\",\n",
            "    \"12\": \"B-corporation\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"B-corporation\": 12,\n",
            "    \"B-creative-work\": 0,\n",
            "    \"B-group\": 5,\n",
            "    \"B-location\": 4,\n",
            "    \"B-person\": 11,\n",
            "    \"B-product\": 1,\n",
            "    \"I-corporation\": 6,\n",
            "    \"I-creative-work\": 10,\n",
            "    \"I-group\": 8,\n",
            "    \"I-location\": 9,\n",
            "    \"I-person\": 7,\n",
            "    \"I-product\": 3,\n",
            "    \"O\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YseNpZLc3a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b8bd25-4ba4-4e58-b33a-7a88871f3c5a"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "  output_dir='./results',          # output directory\n",
        "  num_train_epochs=3,              # total number of training epochs\n",
        "  per_device_train_batch_size=16,  # batch size per device during training\n",
        "  per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "  warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "  weight_decay=0.0001,               # strength of weight decay\n",
        "  logging_dir='./logs',            # directory for storing logs\n",
        "  logging_steps=10,\n",
        "  evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "# In case we want to freeze the pretrained part of a model:\n",
        "# for param in model.base_model.parameters():\n",
        "#     param.requires_grad = False"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUmdID1Vc_ht",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "8307078e-f830-42c9-ff12-7bbb8ef914d1"
      },
      "source": [
        "trainer = Trainer(\n",
        "  model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "  args=training_args,                  # training arguments, defined above\n",
        "  train_dataset=train_dataset,         # training dataset\n",
        "  eval_dataset=val_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 2715\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 510\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='510' max='510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [510/510 01:22, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>0.209598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.097200</td>\n",
              "      <td>0.125589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.072400</td>\n",
              "      <td>0.144984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 679\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 679\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./results/checkpoint-500\n",
            "Configuration saved in ./results/checkpoint-500/config.json\n",
            "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 679\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=510, training_loss=0.3489976295069152, metrics={'train_runtime': 82.7704, 'train_samples_per_second': 98.405, 'train_steps_per_second': 6.162, 'total_flos': 286773158054700.0, 'train_loss': 0.3489976295069152, 'epoch': 3.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw6-IjI0fFQA"
      },
      "source": [
        "model.eval()\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvSFAgiIe2Eu",
        "outputId": "b040ef46-465a-4c4b-a1e4-26925d4ceb30"
      },
      "source": [
        "# example = 'Microsoft moved its headquarters from Bellevue to Redmond, Washington, on February 26, 1986, and went public on March 13.'\n",
        "# example = 'Microsoft released Microsoft Windows on November 20, 1985, as a graphical extension for MS-DOS'\n",
        "# example = 'Huggingface is the best company.'\n",
        "# example = 'Apple Inc. is an American multinational technology company that specializes in consumer electronics, computer software, and online services.'\n",
        "# example = 'Apple has expanded its campuses in Austin, Texas, concurrently with building Apple Park in Cupertino.'\n",
        "example = 'Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very close to the Manhattan Bridge which is visible from the window.'\n",
        "\n",
        "device = \"cuda:0\"\n",
        "with torch.no_grad():\n",
        "  inputs = tokenizer(example, return_tensors=\"pt\").to(device)\n",
        "  outputs = model(**inputs)\n",
        "  softmax = F.softmax(outputs[0][0], dim = 1)\n",
        "  indices = [x.argmax().item() for x in softmax]\n",
        "  input_list = inputs['input_ids'].tolist()[0]\n",
        "  # print(outputs[0][0])\n",
        "  # print(softmax)\n",
        "  print('tags:', id2tag)\n",
        "  print('pred_ids:', indices)\n",
        "  print('input_tokens', input_list)\n",
        "  # print(inputs['input_ids'].tolist()[0])\n",
        "\n",
        "  word2tokens = {x : tokenizer.encode(x, add_special_tokens=False) for x in example.split()}\n",
        "\n",
        "  # print(word2tokens)\n",
        "  # print(tokenizer.decode(101))\n",
        "\n",
        "  for i in range(len(indices)):\n",
        "    print('token: ', input_list[i], '\\ttag: ', id2tag[indices[i]], '  ', 'entity: ', tokenizer.decode(input_list[i]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tags: {0: 'B-creative-work', 1: 'B-product', 2: 'O', 3: 'I-product', 4: 'B-location', 5: 'B-group', 6: 'I-corporation', 7: 'I-person', 8: 'I-group', 9: 'I-location', 10: 'I-creative-work', 11: 'B-person', 12: 'B-corporation'}\n",
            "pred_ids: [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 9, 9, 2, 2, 2, 2, 2, 4, 9, 9, 2, 2, 2, 2, 2, 2, 4, 9, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "input_tokens [101, 20164, 10932, 10289, 3561, 119, 1110, 170, 1419, 1359, 1107, 1203, 1365, 1392, 119, 2098, 3834, 1132, 1107, 141, 25810, 23904, 117, 3335, 1304, 1601, 1106, 1103, 6545, 3640, 1134, 1110, 5085, 1121, 1103, 2487, 119, 102]\n",
            "token:  101 \ttag:  O    entity:  [CLS]\n",
            "token:  20164 \ttag:  O    entity:  Hu\n",
            "token:  10932 \ttag:  O    entity:  ##gging\n",
            "token:  10289 \ttag:  O    entity:  Face\n",
            "token:  3561 \ttag:  O    entity:  Inc\n",
            "token:  119 \ttag:  O    entity:  .\n",
            "token:  1110 \ttag:  O    entity:  is\n",
            "token:  170 \ttag:  O    entity:  a\n",
            "token:  1419 \ttag:  O    entity:  company\n",
            "token:  1359 \ttag:  O    entity:  based\n",
            "token:  1107 \ttag:  O    entity:  in\n",
            "token:  1203 \ttag:  B-location    entity:  New\n",
            "token:  1365 \ttag:  I-location    entity:  York\n",
            "token:  1392 \ttag:  I-location    entity:  City\n",
            "token:  119 \ttag:  O    entity:  .\n",
            "token:  2098 \ttag:  O    entity:  Its\n",
            "token:  3834 \ttag:  O    entity:  headquarters\n",
            "token:  1132 \ttag:  O    entity:  are\n",
            "token:  1107 \ttag:  O    entity:  in\n",
            "token:  141 \ttag:  B-location    entity:  D\n",
            "token:  25810 \ttag:  I-location    entity:  ##UM\n",
            "token:  23904 \ttag:  I-location    entity:  ##BO\n",
            "token:  117 \ttag:  O    entity:  ,\n",
            "token:  3335 \ttag:  O    entity:  therefore\n",
            "token:  1304 \ttag:  O    entity:  very\n",
            "token:  1601 \ttag:  O    entity:  close\n",
            "token:  1106 \ttag:  O    entity:  to\n",
            "token:  1103 \ttag:  O    entity:  the\n",
            "token:  6545 \ttag:  B-location    entity:  Manhattan\n",
            "token:  3640 \ttag:  I-location    entity:  Bridge\n",
            "token:  1134 \ttag:  O    entity:  which\n",
            "token:  1110 \ttag:  O    entity:  is\n",
            "token:  5085 \ttag:  O    entity:  visible\n",
            "token:  1121 \ttag:  O    entity:  from\n",
            "token:  1103 \ttag:  O    entity:  the\n",
            "token:  2487 \ttag:  O    entity:  window\n",
            "token:  119 \ttag:  O    entity:  .\n",
            "token:  102 \ttag:  O    entity:  [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YhMgve2h14Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98532164-06e3-4807-993f-b4cf793cefb1"
      },
      "source": [
        "inputs"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101, 20164, 10932, 10289,  3561,   119,  1110,   170,  1419,  1359,\n",
              "          1107,  1203,  1365,  1392,   119,  2098,  3834,  1132,  1107,   141,\n",
              "         25810, 23904,   117,  3335,  1304,  1601,  1106,  1103,  6545,  3640,\n",
              "          1134,  1110,  5085,  1121,  1103,  2487,   119,   102]],\n",
              "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "fBMjXE9aT4vL",
        "outputId": "9f3c5024-5315-4b6e-e407-51056187eceb"
      },
      "source": [
        "example"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very close to the Manhattan Bridge which is visible from the window.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCmTCB4eQjS-",
        "outputId": "f1f5f0b3-3508-4eaa-fe1e-73c067563b4a"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy='max', device=0, ignore_labels=[])\n",
        "\n",
        "res = ner(example)\n",
        "print(res)\n",
        "\n",
        "print(example)\n",
        "for e in res:\n",
        "  lbl = 'entity' if ner.aggregation_strategy.value == 'none' else 'entity_group'\n",
        "  print(e['start'], '\\t', e['end'], '\\t', e['score'], '\\t',  e[lbl], '\\t', e['word'])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'entity_group': 'O', 'score': 0.73502946, 'word': 'Hugging', 'start': 0, 'end': 7}, {'entity_group': 'O', 'score': 0.31519404, 'word': 'Face', 'start': 8, 'end': 12}, {'entity_group': 'O', 'score': 0.6754972, 'word': 'Inc', 'start': 13, 'end': 16}, {'entity_group': 'O', 'score': 0.9639095, 'word': '.', 'start': 16, 'end': 17}, {'entity_group': 'O', 'score': 0.986017, 'word': 'is', 'start': 18, 'end': 20}, {'entity_group': 'O', 'score': 0.99108684, 'word': 'a', 'start': 21, 'end': 22}, {'entity_group': 'O', 'score': 0.99009395, 'word': 'company', 'start': 23, 'end': 30}, {'entity_group': 'O', 'score': 0.9878843, 'word': 'based', 'start': 31, 'end': 36}, {'entity_group': 'O', 'score': 0.9914327, 'word': 'in', 'start': 37, 'end': 39}, {'entity_group': 'location', 'score': 0.93191975, 'word': 'New York City', 'start': 40, 'end': 53}, {'entity_group': 'O', 'score': 0.9907745, 'word': '.', 'start': 53, 'end': 54}, {'entity_group': 'O', 'score': 0.99356544, 'word': 'Its', 'start': 55, 'end': 58}, {'entity_group': 'O', 'score': 0.9945175, 'word': 'headquarters', 'start': 59, 'end': 71}, {'entity_group': 'O', 'score': 0.99559563, 'word': 'are', 'start': 72, 'end': 75}, {'entity_group': 'O', 'score': 0.98392856, 'word': 'in', 'start': 76, 'end': 78}, {'entity_group': 'location', 'score': 0.755898, 'word': 'DUMBO', 'start': 79, 'end': 84}, {'entity_group': 'O', 'score': 0.99549043, 'word': ',', 'start': 84, 'end': 85}, {'entity_group': 'O', 'score': 0.9969049, 'word': 'therefore', 'start': 86, 'end': 95}, {'entity_group': 'O', 'score': 0.99869883, 'word': 'very', 'start': 96, 'end': 100}, {'entity_group': 'O', 'score': 0.99732286, 'word': 'close', 'start': 101, 'end': 106}, {'entity_group': 'O', 'score': 0.9974459, 'word': 'to', 'start': 107, 'end': 109}, {'entity_group': 'O', 'score': 0.9491126, 'word': 'the', 'start': 110, 'end': 113}, {'entity_group': 'location', 'score': 0.8169936, 'word': 'Manhattan Bridge', 'start': 114, 'end': 130}, {'entity_group': 'O', 'score': 0.9936079, 'word': 'which', 'start': 131, 'end': 136}, {'entity_group': 'O', 'score': 0.9971858, 'word': 'is', 'start': 137, 'end': 139}, {'entity_group': 'O', 'score': 0.995615, 'word': 'visible', 'start': 140, 'end': 147}, {'entity_group': 'O', 'score': 0.9963, 'word': 'from', 'start': 148, 'end': 152}, {'entity_group': 'O', 'score': 0.9974908, 'word': 'the', 'start': 153, 'end': 156}, {'entity_group': 'O', 'score': 0.9952411, 'word': 'window', 'start': 157, 'end': 163}, {'entity_group': 'O', 'score': 0.98779446, 'word': '.', 'start': 163, 'end': 164}]\n",
            "Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very close to the Manhattan Bridge which is visible from the window.\n",
            "0 \t 7 \t 0.73502946 \t O \t Hugging\n",
            "8 \t 12 \t 0.31519404 \t O \t Face\n",
            "13 \t 16 \t 0.6754972 \t O \t Inc\n",
            "16 \t 17 \t 0.9639095 \t O \t .\n",
            "18 \t 20 \t 0.986017 \t O \t is\n",
            "21 \t 22 \t 0.99108684 \t O \t a\n",
            "23 \t 30 \t 0.99009395 \t O \t company\n",
            "31 \t 36 \t 0.9878843 \t O \t based\n",
            "37 \t 39 \t 0.9914327 \t O \t in\n",
            "40 \t 53 \t 0.93191975 \t location \t New York City\n",
            "53 \t 54 \t 0.9907745 \t O \t .\n",
            "55 \t 58 \t 0.99356544 \t O \t Its\n",
            "59 \t 71 \t 0.9945175 \t O \t headquarters\n",
            "72 \t 75 \t 0.99559563 \t O \t are\n",
            "76 \t 78 \t 0.98392856 \t O \t in\n",
            "79 \t 84 \t 0.755898 \t location \t DUMBO\n",
            "84 \t 85 \t 0.99549043 \t O \t ,\n",
            "86 \t 95 \t 0.9969049 \t O \t therefore\n",
            "96 \t 100 \t 0.99869883 \t O \t very\n",
            "101 \t 106 \t 0.99732286 \t O \t close\n",
            "107 \t 109 \t 0.9974459 \t O \t to\n",
            "110 \t 113 \t 0.9491126 \t O \t the\n",
            "114 \t 130 \t 0.8169936 \t location \t Manhattan Bridge\n",
            "131 \t 136 \t 0.9936079 \t O \t which\n",
            "137 \t 139 \t 0.9971858 \t O \t is\n",
            "140 \t 147 \t 0.995615 \t O \t visible\n",
            "148 \t 152 \t 0.9963 \t O \t from\n",
            "153 \t 156 \t 0.9974908 \t O \t the\n",
            "157 \t 163 \t 0.9952411 \t O \t window\n",
            "163 \t 164 \t 0.98779446 \t O \t .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsiORInAd1V2"
      },
      "source": [
        "# # make sense if aggregation_strategy is 'none'\n",
        "# for e in res:\n",
        "#   if 'entity_group' in e:\n",
        "#     e['entity'] = e['entity_group']\n",
        "#     del e['entity_group']\n",
        "# res = ner.group_entities(res)\n",
        "# for e in res:\n",
        "#   print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GVsrCTV7QzF",
        "outputId": "0cc26905-a391-4d7e-9eb3-712d33e162dc"
      },
      "source": [
        "# the list of labels to be ignore added\n",
        "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy='max', device=0, ignore_labels=['O'])\n",
        "\n",
        "res = ner(example)\n",
        "\n",
        "print(example)\n",
        "for e in res:\n",
        "  lbl = 'entity' if ner.aggregation_strategy.value == 'none' else 'entity_group'\n",
        "  print(e['start'], '\\t', e['end'], '\\t', e['score'], '\\t',  e[lbl], '\\t', e['word'])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very close to the Manhattan Bridge which is visible from the window.\n",
            "40 \t 53 \t 0.93191975 \t location \t New York City\n",
            "79 \t 84 \t 0.755898 \t location \t DUMBO\n",
            "114 \t 130 \t 0.8169936 \t location \t Manhattan Bridge\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}